[
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html",
    "href": "template_qmds/04-slr-formalization-notes.html",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#learning-goals",
    "href": "template_qmds/04-slr-formalization-notes.html#learning-goals",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#readings-and-videos",
    "href": "template_qmds/04-slr-formalization-notes.html#readings-and-videos",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-1-get-to-know-the-data",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W‚Äôs + H seem most relevant to our investigations? Explain your thoughts."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet‚Äôs get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe‚Äôd like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-4-filtering-our-data",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-4-filtering-our-data",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We‚Äôll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet‚Äôs fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n## Error in eval(mf, parent.frame()): object 'bikes_sub' not found\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## Error: object 'bike_mod' not found\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n## Error: object 'bike_mod' not found\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-6-predictions-and-residuals",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-6-predictions-and-residuals",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don‚Äôt worry about the syntax ‚Äì we haven‚Äôt learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## Error: object 'bikes_sub' not found\n\n\nPeak back at the scatterplot. Identify which point corresponds to August 17, 2012. Is it close to the trend? Were there more riders than expected or fewer than expected?\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\nCheck your part b calculation using the predict() function. Take careful note of the syntax ‚Äì there‚Äôs a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n## Error: object 'bike_mod' not found\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\nresidual = observed y - predicted y = ???\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\nFor an 85 degree day, how many registered riders would we expect? Do you think it‚Äôs a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-7-changing-temperature-units-challenge",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#reflection",
    "href": "template_qmds/04-slr-formalization-notes.html#reflection",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Reflection",
    "text": "Reflection\nStatistics is a particular kind of language and collection of tools for channeling curiosity to improve our world.\nReview the learning objectives at the top of this file and the flow of today‚Äôs activity. How do the concepts we practiced today facilitate curiosity?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#render-your-work",
    "href": "template_qmds/04-slr-formalization-notes.html#render-your-work",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Render your work",
    "text": "Render your work\n\nClick the ‚ÄúRender‚Äù button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the ‚ÄúBackground Jobs‚Äù pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your ‚ÄúActivities‚Äù subfolder within your ‚ÄúSTAT155‚Äù folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-8-ridership-and-windspeed",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-8-ridership-and-windspeed",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet‚Äôs pull together everything that you‚Äôve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You‚Äôll first need to find the windspeed on this date!)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-9-data-drills-filter-select-summarize",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We‚Äôll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you‚Äôve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 √ó 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 √ó 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 √ó 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-10-your-turn",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-10-your-turn",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#done",
    "href": "template_qmds/04-slr-formalization-notes.html#done",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer ‚Äì check that your work translated correctly; and (3) Outside RStudio, navigate to your ‚ÄòActivities‚Äô subfolder within your ‚ÄòSTAT155‚Äô folder and locate the HTML file ‚Äì you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‚ÄòStop‚Äô button in the ‚ÄòBackground Jobs‚Äô pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Introduction to Statistical Modeling",
    "section": "",
    "text": "Section 03: M/W/F 09:40-10:40am\nSection 04: M/W/F 12:00-01:00pm\nWelcome to Introduction to Statistical Modeling! Whether in life or research, we‚Äôre often interested in relationships between 2+ variables. For example, how is one‚Äôs commute time to class related to their distance from campus and mode of transportation? Or, how is voter participation related to a person‚Äôs age and political affiliation? Statistical modeling is the art and science of turning data into information about such relationships of interest.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today‚Äôs information landscape, and these are precisely the skills that we‚Äôll build in this class. Throughout the semester, we‚Äôll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas."
  },
  {
    "objectID": "syllabus.html#important-technical-concepts",
    "href": "syllabus.html#important-technical-concepts",
    "title": "Introduction to Statistical Modeling",
    "section": "Important technical concepts",
    "text": "Important technical concepts\nUpon completion of this course, students should be able to:\n\nBuild, use, and interpret graphical and numerical summaries of data.\nGiven a research question: identify an appropriate model, use sample data to fit the model in RStudio (for project!), evaluate the model‚Äôs quality, and quantify our uncertainty in the model‚Äôs coefficients and predictions.\nUse a sample model to make predictions & inferences about a population, using prediction/confidence intervals & hypothesis tests.\nInterpret & communicate an analysis in context & using appropriate notation, argumentation, & evidence.\nDescribe potential advantages, limitations, and ethical considerations of a data set and statistical analysis.\nIdentify common pitfalls in statistical analyses (e.g., spurious correlation vs.¬†causal relationships, extrapolation, multicollinearity, multiple testing, practical vs.¬†statistical significance).\nAccurately describe methods and results in a way that is scientifically sound and widely accessible.\nWork productively and effectively in a group setting for the project."
  },
  {
    "objectID": "syllabus.html#important-statistical-skills",
    "href": "syllabus.html#important-statistical-skills",
    "title": "Introduction to Statistical Modeling",
    "section": "Important statistical skills",
    "text": "Important statistical skills\nThe following skills are essential both within and beyond Statistics, and demonstrably improve your own learning and the learning of those around you:\n\nMove beyond a ‚Äúhomework only‚Äù study approach. Develop a deeper understanding of the material through continued review, reflection, and practice.\nThink creatively, and build confidence, applying course concepts in open-ended, novel settings.\nBe comfortable working through challenges and mistakes.\nContribute to a welcoming and engaged learning environment."
  },
  {
    "objectID": "syllabus.html#about-your-professor",
    "href": "syllabus.html#about-your-professor",
    "title": "Introduction to Statistical Modeling",
    "section": "About your professor",
    "text": "About your professor\n\nMd Mutasim Billah, PhD\nPronunciation: listen here\nOffice: My Office\nEmail: mbillah@macalester.edu\n\n\n\n\n\n\nNotes from ‚Äúyour professor‚Äù\n\n\n\nGreetings! You can call me Bill or Professor Billah & I use he/him pronouns. Back when I was an undergrad student, I didn‚Äôt have the best experience in Intro Stat‚Äîthose courses often emphasized formulas over real understanding. That experience has shaped my teaching‚ÄîI concentrate on illustrating how statistical theories connect and can be applied in the real world. I‚Äôm excited to teach Introduction to Statistical Modeling and to create a more meaningful experience‚Äîone that helps all students feel confident applying it beyond the classroom. My methodological research lies at the intersection of statistical genetics, biostatistics, and genomics. My current research interests include developing novel statistical methods and computationally efficient bioinformatics tools, leveraging modern machine- and deep-learning approaches analyze high-dimensional next-generation sequencing and multi-omics data to identify genes and regulatory mechanisms underlying complex diseases. Outside of my academic work, I enjoy spending time outdoors with family and friends or cooking variety of foods. If you can‚Äôt find me anywhere, I might be busy playing soccer or exploring new worlds on my PS5 or PSVR!\n\n\nDrop-in (office) hours:\n\nLocation: My office\nTimes: M/W/F: 01:30-02:30 pm.\nBy Appointment: I‚Äôm also happy to meet one-on-one! Shoot me an email and we can arrange it either in-person or over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays.\nPlease note that messages sent after 5:00 pm or on weekends may take longer to receive a response."
  },
  {
    "objectID": "syllabus.html#about-your-gtas",
    "href": "syllabus.html#about-your-gtas",
    "title": "Introduction to Statistical Modeling",
    "section": "About your GTAs",
    "text": "About your GTAs\nWe have several wonderful GTAs this semester! Their role is to help students with content questions, assist in the navigation of available resources, advise on studying approaches, and assist with concepts, tools, and skills. Students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), they are not expected to immediately know the right approach to an exercise, and they do not provide assistance outside of office hours.\nIn hiring preceptors, we prioritize and emphasize kindness and respect. I expect the same of students in their interactions with the preceptors. Please utilize and respect their experience and commitment to supporting you in this course."
  },
  {
    "objectID": "syllabus.html#online-course-manual",
    "href": "syllabus.html#online-course-manual",
    "title": "Introduction to Statistical Modeling",
    "section": "Online Course Manual",
    "text": "Online Course Manual\nThe online course manual includes all in-class activities (with solutions) and a daily Schedule. All links and materials needed will be provided on the schedule tab of this website."
  },
  {
    "objectID": "syllabus.html#canvasmoodle",
    "href": "syllabus.html#canvasmoodle",
    "title": "Introduction to Statistical Modeling",
    "section": "Canvas/Moodle",
    "text": "Canvas/Moodle\nCanvas/Moodle includes general resources, a broad course calendar, submission links, feedback, and a forum for student questions."
  },
  {
    "objectID": "syllabus.html#statistical-software",
    "href": "syllabus.html#statistical-software",
    "title": "Introduction to Statistical Modeling",
    "section": "Statistical software",
    "text": "Statistical software\nWe will use the (completely free and open source) R programming language for the project in this course. RStudio (an interface for R) will facilitate our use of R. Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nMore detailed instructions on downloading, installing, and getting started with R, and RStudio are available on the R Resources tab."
  },
  {
    "objectID": "syllabus.html#office-hours-oh-and-r-support",
    "href": "syllabus.html#office-hours-oh-and-r-support",
    "title": "Introduction to Statistical Modeling",
    "section": "Office hours (OH) and R Support",
    "text": "Office hours (OH) and R Support\nOH: Across the instructor and GTAs, there are several office hours each week. Names, times, and locations are on the Moodle course calendar. IMPORTANT: Always check the calendar before attending OH."
  },
  {
    "objectID": "syllabus.html#asking-questionscommunicating",
    "href": "syllabus.html#asking-questionscommunicating",
    "title": "Introduction to Statistical Modeling",
    "section": "Asking questions/communicating",
    "text": "Asking questions/communicating\n\nOffice Hours\nOH are a great place to chat about the course, career planning, life,‚Ä¶ Please visit us!!\n\nOH times & locations are on the Canvas/Moodle course calendar.\nOH are oriented around group discussion. They are not first come, first served appointments.\nSince it‚Äôs not an effective way to deepen your learning, OH are not a place to sit and do assignments with me or preceptors. It‚Äôs an opportunity to discuss concepts & specific questions.\n\n\n\nCanvas/Moodle Forum: Discussion Board\nThis forum is where we‚Äôll communicate outside class. Students can post and answer comments / questions there. This is an informal way to converse, ask questions, share info, & connect. Do not rely on receiving responses outside weekdays between 9am & 5pm."
  },
  {
    "objectID": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "href": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "title": "Introduction to Statistical Modeling",
    "section": "What to do when you have a question for me?",
    "text": "What to do when you have a question for me?\n\nIf it‚Äôs non-private (e.g.¬†about policies, homework (Practice Problems), class activities, etc), you must post it on Discussion Board on Canvas/Moodle. Remember- collaboration is the KEY!\nIf it‚Äôs personal (e.g.¬†about an absence), email me.\nIt‚Äôs good, professional practice to check whether your question is already answered in the provided resources. For example:\n\nInfo (what to do if you miss class): syllabus\nDue dates: course calendar at the top of Moodle + course schedule in the online manual\nQuiz dates: syllabus + course calendar at the top of Moodle + course schedule in the online manual\nFinals week: syllabus + course calendar at the top of Moodle + course schedule in the online manual"
  },
  {
    "objectID": "syllabus.html#thriving-in-introduction-to-statistical-modeling",
    "href": "syllabus.html#thriving-in-introduction-to-statistical-modeling",
    "title": "Introduction to Statistical Modeling",
    "section": "Thriving in Introduction to Statistical Modeling",
    "text": "Thriving in Introduction to Statistical Modeling\n\n\n\n\n\n\nüóìÔ∏è Plan Ahead\n\n\n\nYou should plan to spend ~10-12 hours on any 4-credit course, including class time.1 Stay up-to-date on the course calendar and carve out time for studying & doing homework.\n\n\n\n\n\n\n\n\n‚úÖ Do the Things\n\n\n\nAt minimum, thriving in this course requires the completion of some concrete tasks. Complete all assignments, regularly attend & engage in class, complete in-class activities (which might mean completing work outside of class), and check the activity solutions.\n\n\n\n\n\n\n\n\nüèóÔ∏è Build a Foundation\n\n\n\nIf your main focus is on checking off some boxes, you won‚Äôt get much out of this course (or college in general). Deeper, enduring learning requires more. Carve out time to rewrite, reflect upon, & review your notes. Summarize concepts in your own words.\n\n\n\n\n\n\n\n\nüéâ Engage, Ask Questions, Have Fun\n\n\n\nActively participate in the class & take ownership of your learning. PLEASE: Don‚Äôt be afraid to ask for help, make mistakes, and ask questions! These skills are critical to your well-being & learning. Finally, have some fun, be curious, and reflect upon what surprises you about the material and yourself"
  },
  {
    "objectID": "syllabus.html#flexibility",
    "href": "syllabus.html#flexibility",
    "title": "Introduction to Statistical Modeling",
    "section": "Flexibility",
    "text": "Flexibility\nI provide transparent accommodations to all students. It helps reduce stress and the ‚Äúhidden curriculum‚Äù (not everybody feels comfortable asking for flexibility).\n\nMissed Class: It‚Äôs okay to miss class in the case of an emergency. Please see the ‚ÄòAbsences‚Äô tab below for details.\nPractice Problems (PP): Limited extensions and limited mistakes without penalty.\nCheckpoints: Some class periods will have course videos and readings assigned ahead of time. For each class period where this is the case, a checkpoint quiz (on Canvas/Moodle) must be completed by 09:00 am. Checkpoints may be attempted as many times as you‚Äôd like, but to earn completion credit for a given checkpoint you must score 100% by your final attempt. These short quizzes are designed to ensure that you stay on top of course material, since much of the content in this course builds on itself.\nQuizzes: Limited revisions. Additional flexibility will be provided in rare extenuating circumstances, upon discussion. Exceptions must be discussed with me (not assumed) early on (not after the fact).\n\n\n\n\n\n\n\nü§ù PLEASE REACH OUT WHEN YOU NEED HELP."
  },
  {
    "objectID": "syllabus.html#absences",
    "href": "syllabus.html#absences",
    "title": "Introduction to Statistical Modeling",
    "section": "Absences",
    "text": "Absences\nIt‚Äôs okay to miss the occasional class. Except in rare extenuating circumstances (which must be discussed in advance): - 3 or fewer absences will not impact your grade - 4-6 absences will impact your grade (see Calculating Final Grades section) - you cannot pass the course if you accrue 7+ absences (more than 25% of class sessions)\n\n\n\n\n\n\nWhat to Do If You Miss Class\n\n\n\n\nüìß Send me a quick email. You do not need to share a reason for your absence, especially if it‚Äôs personal. It‚Äôs just a simple courtesy & keeps communication lines open.\nüìÖ Check the Course Schedule in the online manual for what is happening in class that day.\nüìù Complete the in-class activity on your own & check the solutions posted in the online manual.\nüí¨ Ask any follow-up questions on the Moodle forum or in office hours (OH)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai",
    "href": "syllabus.html#artificial-intelligence-ai",
    "title": "Introduction to Statistical Modeling",
    "section": "Artificial Intelligence (AI)",
    "text": "Artificial Intelligence (AI)\nUsing AI tools is an emerging skill. You may use AI (ChatGPT, Gemini, Grok, etc), with some caveats & limitations:\n\nAI is often wrong, thus is not a good resource on topics for which you don‚Äôt yet have expertise. Relatedly, though AI can be helpful with parts of a statistical analysis (eg: getting unstuck on code, checking grammar), you have to guide that process (eg: what questions are we trying to answer? what‚Äôs a reasonable approach?).\nWork on an exercise for at least 30 minutes before even thinking about AI. You will learn very little if you overly rely on AI, hence be unprepared for other interactions with the material (eg: in-class discussions, quizzes, future courses that build upon 155, etc). Learning comes from you doing the puzzling, not from you producing a correct answer.\nWhether or not you use AI, you must be able to defend/explain any code/discussion you hand in. You cannot simply use AI to bypass your own learning.\nYou may not use AI to generate entire arguments or discussions. Putting code and discussions into your own words is critical for your own deeper learning, independent thinking, and creativity. (For example, imagine how little you‚Äôd learn in a language course if you simply used AI to translate all text for you!!)\nAny use of AI must be cited, just like any other resource. Using AI without citation, to generate entire discussions / code blocks, or without being able to defend the results. Policy violations will result in a score of 0 on the work & be reported to the Asst. Dean of Academic Programs & Advising."
  },
  {
    "objectID": "syllabus.html#engagement",
    "href": "syllabus.html#engagement",
    "title": "Introduction to Statistical Modeling",
    "section": "(1) Engagement",
    "text": "(1) Engagement\nEngagement is important to your own learning & to fostering a supportive learning community.\n\n\n\n\n\n\nüìå Expectations\n\n\n\n\nDo not miss more than 3 in-person class sessions. (4‚Äì6 absences will lower your grade. 7+ absences will result in a D/NC.)\nWhen attending class:\n\nBe on time & don‚Äôt leave early\n\nDo not use your phone (phones must be put away when you enter the course, even if class hasn‚Äôt started)\n\nDo not use your laptop for anything other than taking notes and in-class activities (e.g., no videos, no email, no messaging apps, etc.)\n\nBe actively present (e.g., don‚Äôt work alone, don‚Äôt work on other courses, etc.)\n\nOutside class:\n\nCheck your email for announcements (sent via Moodle) and stay updated on the Moodle forum\n\nWhen you have questions, or just want to chat, please stop by OH!"
  },
  {
    "objectID": "syllabus.html#collaboration",
    "href": "syllabus.html#collaboration",
    "title": "Introduction to Statistical Modeling",
    "section": "(2) Collaboration",
    "text": "(2) Collaboration\nCollaboration improves higher-level thinking, confidence, communication, community, & more. You will work in groups in and outside class. These groups may occasionally switch & may sometimes be assigned.\n\n\n\n\n\n\nü§ù Expectations\n\n\n\n\nIn group settings(for the project), both in and outside class, you:\n\nUse your group members‚Äô correct names and pronouns\n\nActively contribute to discussions\n\nActively include all other group members in discussion\n\nCreate a space where others feel comfortable making mistakes & sharing their ideas\n\nEffectively communicate with your group about meeting times, etc."
  },
  {
    "objectID": "syllabus.html#preparation-checkpoints",
    "href": "syllabus.html#preparation-checkpoints",
    "title": "Introduction to Statistical Modeling",
    "section": "(3) Preparation (Checkpoints)",
    "text": "(3) Preparation (Checkpoints)\nBefore class you will watch videos which introduce new concepts, then take a low-stakes checkpoint quiz (CP). This will help us prepare for class, build a common foundation, & maximize our time together ‚Äì just how readings & reading reflections might be used in another class!\n\n\n\n\n\n\nüìä Expectations\n\n\n\nComplete at least 13 (out of 17) CPs (‚âà80%) without affecting your final grades!\n\n\n\n\n\n\n\n\nüìú Policies\n\n\n\n\nCPs may be attempted as many times as you‚Äôd like, but to earn completion credit for a given checkpoint you must score 100% by your final attempt.\nIf you complete less than 13 (out of 17) CPs (‚âà80%) before the time they are due, your overall course grade will be lowered by 1/3 of a letter grade (i.e.¬†B ‚Äì&gt; B-, A- ‚Äì&gt; B+, etc.).\n\nIf you complete less than 8 (out of 17) CPs (‚âà50%) before the time they are due, your overall course grade will be lowered by 1 of a letter grade (i.e.¬†A ‚Äì&gt; B, etc.).\n\nCPs are due 09:00am on the assigned date. There are no extensions for CPs, as they are important preparation for the relevant class session."
  },
  {
    "objectID": "syllabus.html#practice-problems-and-homeworks",
    "href": "syllabus.html#practice-problems-and-homeworks",
    "title": "Introduction to Statistical Modeling",
    "section": "(4) Practice Problems and Homeworks",
    "text": "(4) Practice Problems and Homeworks\nFor each Unit, you will have practice problem sets to practice- the solution will be posted as well in the course website. Besides, you also will have Homework for each unit.\n\nGrading: HW grades will be based on Exercises & Presentation.\nExtensions: Limited extensions will be provided.\nDiscussion Board: Use the Canvas/Moodle board as your first stop for Practice Problems (PP):\n\nAsk first: Post questions about PP on Moodle. Include the problem number, a brief summary of your approach, and where you‚Äôre stuck. For coding, share the entire code chunk for the related problem.\nHelp each other: If you know (or suspect) the answer, reply! Explaining your reasoning helps everyone learn.\nShare alternatives: Multiple correct methods are welcome‚Äîpost yours with explanation.\nShow your work: To earn full collaboration credit, provide complete, well-explained solutions/steps. Partial or unexplained answers may lose points.\nBe professional: Be respectful, cite any resources you used, and write solutions in your own words.\nGoal: work together as a class so everyone can earn the PP points while learning deeply."
  },
  {
    "objectID": "syllabus.html#project-independence-application",
    "href": "syllabus.html#project-independence-application",
    "title": "Introduction to Statistical Modeling",
    "section": "(5) Project (Independence & Application)",
    "text": "(5) Project (Independence & Application)\nMore details will be provided later in the semester. Here are some basics:\n\nWe‚Äôll start working on projects in ~week 6, with the majority of the work happening later in the semester.\nThe projects are collaborative. You will be working in groups. Though you will work in assigned groups at various points throughout the semester, you will pick your own group for the project. This is something to think about as you meet other students in class and learn about common interests.\nProject grades will be based upon a final group written report (no oral presentation), multiple group and individual checkpoints, and individual contributions to the project (thus it‚Äôs possible for different group members to earn different grades)."
  },
  {
    "objectID": "syllabus.html#quizzes-content-expertise",
    "href": "syllabus.html#quizzes-content-expertise",
    "title": "Introduction to Statistical Modeling",
    "section": "(6) Quizzes (Content Expertise)",
    "text": "(6) Quizzes (Content Expertise)\nYour course engagement, collaboration, preparation, practice, and application will support your deeper understanding of the course material. This will be assessed through three in-person quizzes. You must schedule all travel and other commitments around them ‚Äî there will not be any alternative quiz times.\n\nQuiz 1: TBD\nQuiz 2: TBD\nQuiz 3: TBD\n\n\n\n\n\n\n\nüìú Quiz Policies\n\n\n\n\nAll quizzes will have the following format:\n\nTaken individually, using pen/pencil & paper\n\nYou will not need to write code or use a calculator, but you will need to read & interpret R output\n\nClosed notes, but you may use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards. Making your own card is important to the review process- as you are required to submit the index card along with the answer paper.\n\nQuizzes 2 & 3 will be cumulative. This is unavoidable as the material builds upon itself.\nQuiz corrections:\nYou can earn up to 33% of missed points back on Quizzes 1 & 2 if you:\n\nWrite a reflection of how you prepared for the quiz and where you felt strongest or more uncertain in your understanding before taking the quiz; and\n\nSubmit your quiz corrections along with your reflection to the instructor, no later than one week after quizzes have been handed back.\nNote: Quiz 3 corrections are not allowed due to time constraints at the end of the semester."
  },
  {
    "objectID": "syllabus.html#grading-system",
    "href": "syllabus.html#grading-system",
    "title": "Introduction to Statistical Modeling",
    "section": "Grading system",
    "text": "Grading system\nThe grading system in this course is designed to help you achieve the learning objectives while allowing space to make and learn from mistakes along the way. Your final course grade will consist of three, evenly-weighted components (Quizzes, Practice Problems, and the Project), modified by your progress toward the Engagement, Collaboration, and Preparation (Checkpoint) goals:\n\n\n\nCourse Percentage\n25% Homeworks +\n50% Quiz total +\n25% Project\n\n\n\nGrade\nCourse percentage\n\n\n\n\nA\n&gt; 90%\n\n\nAB\n85‚Äì90%\n\n\nB\n80‚Äì85%\n\n\nBC\n75‚Äì80%\n\n\nC\n70‚Äì75%\n\n\nCD\n65‚Äì70%\n\n\nD\n60‚Äì65% or 7+ absences\n\n\nF\n0‚Äì60%\n\n\n\n\n\n¬† \n\n\nGrade Modifiers\nEngagement (including attendance) +\nPreparation (checkpoints)\n\n\n\n\n\n\n\nModifier\nScenario\n\n\n\n\nnone (e.g.¬†A ‚Üí A)\nMeets expectations in all two areas (Engagement and Preparation)\n\n\n‚Öì lower grade (e.g.¬†A ‚Üí A-)\nDemonstrates strong progress (e.g., 4 absences OR less than 13 (out of 17) CPs (‚âà80%))\n\n\n1 lower grade (e.g.¬†A ‚Üí B)\nDemonstrates moderate progress (e.g., 5‚Äì6 absences OR less than 8 (out of 17) CPs (‚âà50%))\n\n\n&gt;1 lower grade\nDemonstrates little progress toward expectations in two areas\n\n\nDrop to D\nHas 7+ absences\n\n\n\nNOTE: The table presents general scenarios. Please reach out if you want to discuss progress in Engagement and/or Preparation.\n\n\n\n\n\n\n\n\n\nüìä Grading Caveats\n\n\n\n\nThe goal of sharing this specific information is to provide transparency around final grades, hence clear goals to work toward. That said, assigning grades is much more nuanced than any grading rubric / framework might suggest (for good reasons). What‚Äôs shared here is a worst case scenario ‚Äì it represents the lowest a grade might be if you meet the corresponding goals.\nMoodle does NOT correctly weight your grades, thus should not be used alone to monitor your progress."
  },
  {
    "objectID": "syllabus.html#what-to-do-if-you-miss-class",
    "href": "syllabus.html#what-to-do-if-you-miss-class",
    "title": "Introduction to Statistical Modeling",
    "section": "What to Do If You Miss Class",
    "text": "What to Do If You Miss Class\nIf you do miss class, I expect you to complete any in-class activities on your own. Check the solutions in the online manual and come to office hours with any follow-up questions."
  },
  {
    "objectID": "syllabus.html#late-work-on-homework-problems",
    "href": "syllabus.html#late-work-on-homework-problems",
    "title": "Introduction to Statistical Modeling",
    "section": "Late work on Homework Problems",
    "text": "Late work on Homework Problems\nThroughout the semester, you may use up to three, three-day extensions. These three extensions can be used on Homeworks only, not quizzes. The purpose of deadlines (and extensions) are to keep you accountable for your own learning, to keep you on track with the pace of the course (which builds upon itself throughout the semester), and to provide preceptors and myself with the ability to provide you with timely feedback on assignments. Since the Problem Sets are due roughly every two weeks, you must begin working on them early if you want to succeed.\nExtensions can be used automatically, without letting me know in advance. The Moodle dropboxes for assignments will close exactly 3 days after the original deadline (i.e.¬†Mondays at 11:59pm), and I will not accept work submitted after that point unless there are extenuating circumstances that you have communicated with me about ahead of the original deadline. If you email me a completed assignment after a 3-day extension is up, I may have the preceptors provide you with feedback, but you will not receive credit for the assignment (equivalent to ‚ÄúNeeds Improvement‚Äù on every question of the relevant assignment).\nI expect you to keep track of how many extensions you‚Äôve used. I will do my best to email you a reminder if you have used all three of your extensions and have none remaining.\nIf you have run out of extensions and/or an extenuating circumstance occurs that impacts your ability to submit assignments on time, please email me to discuss the situation. I am happy to be flexible as long as you communicate!"
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": "Introduction to Statistical Modeling",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations.\nIn an effort to respect religious diversity, I request that students who plan to observe a religious holiday during scheduled class meetings/class requirements talk to me about reasonable consideration by the end of the second week of the course."
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": "Introduction to Statistical Modeling",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others‚Äô ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Introduction to Statistical Modeling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMacalester Academic Advising ‚Äì High School Preparation‚Ü©Ô∏é"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Details are coming soon‚Ä¶"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Statistical Modeling",
    "section": "",
    "text": "Introduction to Statistical Modeling\nUniversity of Kentucky, Spring 2026\nStatistics is not just about theories & numbers ‚Äî it‚Äôs about making sense of the world.\n\n\n\n\n\n\nüìñ A Thought from H. G. Wells\n\n\n\n\n‚ÄúStatistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.‚Äù\n\n\n\nWelcome to the world of Statistics! In this course, you‚Äôll learn how to analyze data, test research hypotheses, and make predictions in ways that matter.\nInstructor: Md Mutasim Billah  Class meeting times:\n\nSection 03: M/W/F 09:40-10:40am\nSection 04: M/W/F 12:00-01:00pm\n\nInstructor‚Äôs drop-in (office) hours:\n\nLocation: My office\nTimes: M/W/F: 01:30-02:30 pm.\nBy Appointment: I‚Äôm also happy to meet one-on-one! Shoot me an email and we can arrange it either in-person or over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays.\nPlease note that messages sent after 5:00 pm or on weekends may take longer to receive a response.\n\n\nGTA Office Hours: There is a link to a Google Calendar containing all GTA office hours available at the top of the course Canvas/Moodle page!\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email mbillah@macalester.edu"
  },
  {
    "objectID": "activities/05-slr-model-eval.html",
    "href": "activities/05-slr-model-eval.html",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#learning-goals",
    "href": "activities/05-slr-model-eval.html#learning-goals",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#readings-and-videos",
    "href": "activities/05-slr-model-eval.html#readings-and-videos",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the ‚ÄúLadder of Power‚Äù in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#model-assumptions",
    "href": "activities/05-slr-model-eval.html#model-assumptions",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nOne way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are ‚Äúwrong‚Äù, ‚Äústrong‚Äù, and ‚Äúfair‚Äù approaches this from one perspective. To the first question (whether our model is wrong), recall the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell ‚ÄúLINE‚Äù (how convenient!).\nBy assumptions, we mean that the above four ‚Äúthings‚Äù are needed mathematically in order for linear regression to ‚Äúwork‚Äù.\nWhereas we can check some of these assumptions using a residual plot, we need to examine the context of our data collection when checking the Independence assumption. What we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person‚Äôs high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we‚Äôll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse‚Äôs weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse‚Äôs weight one day is certainly not independent of it‚Äôs weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include ‚ÄúMouse ID‚Äù as a predictor in our regression model (again, we‚Äôll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "href": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nLet‚Äôs revisit the Capital Bikeshare data:\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nWe previously explored a model of daily ridership among registered users as a function of temperature:\n\n# Fit a linear model\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check it out\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nPlot this relationship with both a curved and linear trend line. Based on this plot, do you think the model is correct? If not, which of the LINE assumptions does it violate?\n\n# Plot temp_feel vs riders_registered with a model trend\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_smooth(se = FALSE, color = \"red\")"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-2-residual-plots",
    "href": "activities/05-slr-model-eval.html#exercise-2-residual-plots",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nPlotting the residuals vs the predictions (also called ‚Äúfitted values‚Äù) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plot for bike_model. As with the scatterplot, this plot indicates that bike_model violates one of the LINE assumptions. Explain which assumption that is and how you can tell that from just the residual plot.\nNotes:\n\nInformation about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\nWe can fix this model by adding a quadratic ‚Äútransformation term‚Äù (Next CP quiz topic!).\n\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) + # Check this first!\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "href": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 3: What‚Äôs incorrect about this model?",
    "text": "Exercise 3: What‚Äôs incorrect about this model?\nConsider another example. The mammals data includes data on the average brain weight (g) and body weight (kg) for a variety of mammals:\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 √ó 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\nFit a model of brain vs body weight:\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nConstruct two plots that will help us evaluate mammal_model:\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\n\n\n# Residual plot for mammal_model\n\n\nThese two plots confirm that our model is wrong. What is wrong? That is, which of the LINE assumptions are violated? (NOTE: We again can fix this model by ‚Äútransforming‚Äù one or both of the brain and body variables (next CP quiz topic!)."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals",
    "href": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nJust for fun, let‚Äôs dig into the mammals data. Discuss what you observe:\n\n# Label the points by the animal name!\n# Discuss: What 2 things are new in this code?\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    geom_smooth(method = \"lm\", se = FALSE) \n\n\n\n\n\n\n\n\n\n# Zoom in\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 1500), x = c(0, 600))\n\n\n\n\n\n\n\n\n\n# Zoom in more\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 500), x = c(0, 200))"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the variation in the predictors.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that‚Äôs explained by the model (the variance of the predictions) and the variability that‚Äôs left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\nStrong models have residuals that don‚Äôt deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\]\n\n\n\n\n\n\nR-squared\n\n\n\n\n\n\\[\nR^2 = 1 - \\frac{SSE}{SSTO} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n\\] where \\(y_i\\) are our observed outcomes, \\(i = 1, \\dots, n\\), \\(\\hat{y}_i\\) are our fitted values/predictions, and \\(\\bar{y}\\) is our observed average outcome."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "href": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\nRecall bikemod1 from Exercise 1, where we predicted registered riders by what the temperature felt like on a given day. Use the summary function to look out the model output for bikemod1, and interpret the \\(R^2\\) value for this model, in the context of the problem. (NOTE: \\(R^2\\) is reported in output here as ‚ÄúMultiple R-squared‚Äù).\n\n# Get R-squared\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "href": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we‚Äôll look at data from a synthetic dataset called Anscombe‚Äôs quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the ‚ÄúEstimate‚Äù column of the ‚ÄúCoefficients:‚Äù part) and the ‚ÄúMultiple R-squared‚Äù value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\nComplete Exercise 8-11 after the class."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "href": "activities/05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 8: Biased data, biased results: example 1",
    "text": "Exercise 8: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for ‚Äústatistics professor.‚Äù What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "href": "activities/05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 9: Biased data, biased results: example 2",
    "text": "Exercise 9: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the r√©sum√©s of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the r√©sum√©})\\]\nSkim this Reuter‚Äôs article about the company‚Äôs r√©sum√© model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "href": "activities/05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 10: Rigid data collection systems",
    "text": "Exercise 10: Rigid data collection systems\nWhen working with categorical variables, we‚Äôve seen that our units of observation fall into neat groups. Reality isn‚Äôt so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on ‚ÄúWhat gets counted counts‚Äù."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "href": "activities/05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 11: Presenting data: ‚ÄúElevating emotion and embodiment‚Äù",
    "text": "Exercise 11: Presenting data: ‚ÄúElevating emotion and embodiment‚Äù\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we‚Äôve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868‚Äì1963), a ‚Äúsociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor‚Äù1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that ‚ÄúI wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.‚Äù That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e.¬†the value of ‚Äúmultiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.‚Äù"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "href": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nThe red curved trend line shows a clear downward trend around 85 degrees, which contextually makes plenty of sense‚Äîextremely hot days would naturally see less riders. Overall the combination of the upward trend and downward trend makes for a curved relationship that is not captured well by a straight line of best fit. Specifically, a simple linear regression model would violate the Linearity assumption.\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE, color = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-2-residual-plots-1",
    "href": "activities/05-slr-model-eval.html#exercise-2-residual-plots-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nThe residual plot shows a lingering trend in the residuals‚Äîthe blue curve traces the trend in the residuals, and it does not lie flat on the y = 0 line. This again suggests that the Linearity assumption is violated.\n\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "href": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 3: What‚Äôs incorrect about this model?",
    "text": "Exercise 3: What‚Äôs incorrect about this model?\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 √ó 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\nggplot(mammals, aes(y = brain, x = body)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n# Residual plot for mammal_model\nggplot(mammal_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\nThe biggest issue here is that the assumption of equal variance is violated. There‚Äôs much greater variability in the residuals as the predictions increase. This is because there‚Äôs much greater variability in the brain weights (y) as body weights (x) increase."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "href": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nAnswers will vary."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "href": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that‚Äôs explained by the model (the variance of the predictions) and the variability that‚Äôs left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n‚ÄúGood‚Äù models have residuals that don‚Äôt deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe first row corresponds to the weaker model. We can tell because the points are much more dispersed from the trend line than in the second row. Recall that the correlation metric measures how closely clustered points are about a straight line of best fit, so we would expect the correlation to be lower for the first row than the second row.\nThe variance of the residuals is much lower for the second row‚Äîthe residuals are all quite small. This indicates a stronger model."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "href": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\n\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nMultiple R-squared: 0.2961\nInterpretation: 29.61% of the variation in number of registered riders on any given day can be explained by the variation in temperature (specifically, what temperature it ‚Äúfeels‚Äù like it is)."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "href": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we‚Äôll look at data from a synthetic dataset called Anscombe‚Äôs quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\nhead(anscombe)\n##   x1 x2 x3 x4   y1   y2    y3   y4\n## 1 10 10 10  8 8.04 9.14  7.46 6.58\n## 2  8  8  8  8 6.95 8.14  6.77 5.76\n## 3 13 13 13  8 7.58 8.74 12.74 7.71\n## 4  9  9  9  8 8.81 8.77  7.11 8.84\n## 5 11 11 11  8 8.33 9.26  7.81 8.47\n## 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nAll of these models have close to the same intercept, slope, and R-squared!\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nBut when we look at the scatterplots, they all look substantially different, and we would want to approach our modeling differently for each one:\n\nx1 and y1: A linear model seems appropriate for this data.\nx2 and y2: The scatterplot is clearly curved‚Äîa ‚Äúlinear‚Äù regression model with squared terms, for example, would be more appropriate for this data. (We‚Äôll talk more about ways to handle nonlinear relationships soon!)\nx3 and y3: There is a very clear outlier at about x3 = 13 that we would want to dig into to better understand the context. After that investigation, we might consider removing this outlier and refitting the model.\nx4 and y4: There is clearly something strange going on with most of the cases having an x4 value of exactly 8. We would not want to jump straight into modeling. Instead, we should dig deeper to find out more about this data.\n\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercises-8---11",
    "href": "activities/05-slr-model-eval.html#exercises-8---11",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercises 8 - 11",
    "text": "Exercises 8 - 11\nNo solutions for these exercises. These require longer discussions, not discrete answers."
  },
  {
    "objectID": "activities/05-slr-model-eval.html#footnotes",
    "href": "activities/05-slr-model-eval.html#footnotes",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois‚Ü©Ô∏é"
  },
  {
    "objectID": "R_Resources.html",
    "href": "R_Resources.html",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "RStudio cheatsheets\nGoogle it! If you have a question about R, someone else probably asked it. Add ‚ÄúR tidyverse‚Äù to your search term.\nExample: scatterplot R tidyverse\nNote about ChatGPT for code: Please avoid using ChatGPT as a first resort for R code. It often suggests overly wordy or unfamiliar approaches. Our goal is for you to understand the code you write; sticking to tools and syntax we use in class will support your learning best.\nMore details will be shared soon as we begin the project."
  },
  {
    "objectID": "R_Resources.html#getting-help",
    "href": "R_Resources.html#getting-help",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "RStudio cheatsheets\nGoogle it! If you have a question about R, someone else probably asked it. Add ‚ÄúR tidyverse‚Äù to your search term.\nExample: scatterplot R tidyverse\nNote about ChatGPT for code: Please avoid using ChatGPT as a first resort for R code. It often suggests overly wordy or unfamiliar approaches. Our goal is for you to understand the code you write; sticking to tools and syntax we use in class will support your learning best.\nMore details will be shared soon as we begin the project."
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html",
    "href": "activities/03_04-slr-intro-formalization.html",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#learning-goals",
    "href": "activities/03_04-slr-intro-formalization.html#learning-goals",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#readings-and-videos",
    "href": "activities/03_04-slr-intro-formalization.html#readings-and-videos",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through after class. CP Quiz due on Wednesday at 09:00 am on these topics\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W‚Äôs + H seem most relevant to our investigations? Explain your thoughts.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet‚Äôs get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the pclot and numerical summaries.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#a-little-bit-of-live-note-taking",
    "href": "activities/03_04-slr-intro-formalization.html#a-little-bit-of-live-note-taking",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "A little-bit of Live Note Taking!",
    "text": "A little-bit of Live Note Taking!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#before-starting-the-exercise-lets-do-the-followings-first",
    "href": "activities/03_04-slr-intro-formalization.html#before-starting-the-exercise-lets-do-the-followings-first",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Before starting the Exercise, let‚Äôs do the followings first!",
    "text": "Before starting the Exercise, let‚Äôs do the followings first!\nMost of you should have figured out the followings by now, still let‚Äôs skim through the followings!\n\nFirst, save this activity in your device as STAT 155 -&gt; activities -&gt; copy-paste 03_04.qmd\nClick on Render button! What happens? ::: {.callout-tip title=‚ÄúAnswers‚Äù} The html has saved in the same location (folder) where you initially saved the .qmd file! You need to submit .html file like this for the PP! :::\nNow, click on the +C at the top right side of RStudio and then choose R. What happens?\n\n\n\n\n\n\n\nAnswers\n\n\n\nIt creates code chunks",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe‚Äôd like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\nType-in the followings in the.qmd file you have been working from the last class!\n\n\n\n\n\n\nComments\n\n\n\nTrend: Linear (?); Direction/Association: Positive/Negative, Strength: spread of the points (dispersed? close together? moderately close together?); Outlier?\n\n\n\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\nWhat do you think ‚Äúeval = TRUE/FALSE‚Äù doing here {r eval = TRUE/FALSE}?\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\n\n\n\n\n\n\nComments: If we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\nCompute Correlation of temp_feel and riders_registered.\n\n\nCorrelation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a ‚Äúcorrelation coefficient‚Äù or ‚ÄúPearson‚Äôs correlation‚Äù). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a ‚ÄúMath Box‚Äù. You‚Äôll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e.¬†how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e.¬†does y go ‚Äúup‚Äù when x goes ‚Äúup‚Äù (positive), or does y go ‚Äúdown‚Äù when x goes ‚Äúup‚Äù (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\nWhiteboard Time (a little-bit!)\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\nbikes %&gt;%\n    summarize(cor(temp_feel, riders_registered))\n## # A tibble: 1 √ó 1\n##   `cor(temp_feel, riders_registered)`\n##                                 &lt;dbl&gt;\n## 1                               0.544",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#see-class-notes-slr-formalization",
    "href": "activities/03_04-slr-intro-formalization.html#see-class-notes-slr-formalization",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "See class-notes: SLR Formalization",
    "text": "See class-notes: SLR Formalization",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We‚Äôll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees.\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)\n\nDid it work? Check the dimensions of bikes and bikes_sub!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet‚Äôs fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3681.8  -928.3   -98.6   904.9  3496.7 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\n## temp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1267 on 428 degrees of freedom\n## Multiple R-squared:  0.2949, Adjusted R-squared:  0.2933 \n## F-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\n## temp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders‚Äîa negative number of riders doesn‚Äôt make sense! This results because of extrapolation‚Äî0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don‚Äôt worry about the syntax ‚Äì we haven‚Äôt learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## # A tibble: 1 √ó 2\n##   riders_registered temp_feel\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      53.8\n\n\nPeak back at the scatterplot. More riders than expected ‚Äì the point is far above the trend line.\n\n\nggplot(bikes_sub, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) \n\n\n\n\n\n\n\n\n\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\n\n\n\n\n\n\n\nAnswer\n\n\n\n-2486.41180 + 86.49251 * 53.816 = 2168.269\n\n\n\nCheck your part b calculation using the predict() function. Take careful note of the syntax ‚Äì there‚Äôs a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n##        1 \n## 2168.269\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\n\n\n\n\n\n\n\nAnswer\n\n\n\nresidual = observed y - predicted y = 5665 - 2168.269 = 3496.731\n\n\n\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\nPositive residuals are above the trend line‚Äîwe under-estimate ridership.\nNegative residuals are below the trend line‚Äîwe over-estimate ridership.\n\n\n\n\nFor an 85 degree day, how many registered riders would we expect? Do you think it‚Äôs a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.) [Complete after the class!]",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Changing temperature units (CHALLENGE) [Complete after the class!]",
    "text": "Exercise 7: Changing temperature units (CHALLENGE) [Complete after the class!]\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#render-your-work-again-this-is-a-good-practice-to-render-often--to-see-which-part-of-the-paragraph-might-cause-non-rendering-if-applicable-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#render-your-work-again-this-is-a-good-practice-to-render-often--to-see-which-part-of-the-paragraph-might-cause-non-rendering-if-applicable-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Render your work Again (this is a good practice to render often- to see which part of the paragraph might cause non-rendering, if applicable!) [Complete after the class!]",
    "text": "Render your work Again (this is a good practice to render often- to see which part of the paragraph might cause non-rendering, if applicable!) [Complete after the class!]\n\nClick the ‚ÄúRender‚Äù button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the ‚ÄúBackground Jobs‚Äù pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your ‚ÄúActivities‚Äù subfolder within your ‚ÄúSTAT155‚Äù folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet‚Äôs pull together everything that you‚Äôve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You‚Äôll first need to find the windspeed on this date!)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize-complete-after-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize-complete-after-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Data drills (filter, select, summarize) [Complete after class]",
    "text": "Exercise 9: Data drills (filter, select, summarize) [Complete after class]\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We‚Äôll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you‚Äôve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 √ó 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 √ó 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 √ó 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Your turn [Complete after the class!]",
    "text": "Exercise 10: Your turn [Complete after the class!]\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green ‚ÄúC‚Äù button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the ‚ÄúHow does this site work? Do you just download results from the federations?‚Äù question. What do you learn about data quality and completeness from this response?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n## Error in `mutate()`:\n## ‚Ñπ In argument: `NEW_VARIABLE_NAME = Age/BestSquatKg`.\n## Caused by error:\n## ! object 'BestSquatKg' not found\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg.\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet‚Äôs get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe‚Äôd like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a ‚Äúpoint cloud‚Äù) allows us to do this! The code below creates a scatterplot of body weight vs.¬†SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nThis is your second (!) bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we‚Äôve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e.¬†would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a ‚Äúcorrelation coefficient‚Äù or ‚ÄúPearson‚Äôs correlation‚Äù). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a ‚ÄúMath Box‚Äù. You‚Äôll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e.¬†how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e.¬†does y go ‚Äúup‚Äù when x goes ‚Äúup‚Äù (positive), or does y go ‚Äúdown‚Äù when x goes ‚Äúup‚Äù (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## # A tibble: 1 √ó 1\n##   `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n##                                            &lt;dbl&gt;\n## 1                                        -0.0392\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We‚Äôll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we‚Äôll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn‚Äôt obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you‚Äôd like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#reflection",
    "href": "activities/03_04-slr-intro-formalization.html#reflection",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today‚Äôs activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-lines-of-best-fit",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-lines-of-best-fit",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we‚Äôve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is ‚Äúbest‚Äù, and what does ‚Äúbest‚Äù even mean?\nFor this exercise, we‚Äôll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\n\n\n\n\n\n\n\nDescribe the line that you see. Do you think the line is ‚Äúgood‚Äù? What are you using to define ‚Äúgood‚Äù?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we‚Äôll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\n\n\n\n\n\n\n\nIt‚Äôs usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\n\n\n\n\n\n\n\nIn the next activity, we‚Äôll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We‚Äôll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we‚Äôll explore how correlation changes with the addition of extreme values, or observations. We‚Äôll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs.¬†y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs.¬†y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs.¬†y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-2",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-2",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\ndim(bikes)\n## [1] 731  15\n\nhead(bikes)\n## # A tibble: 6 √ó 15\n##   date       season  year month day_of_week weekend holiday temp_actual\n##   &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;   &lt;chr&gt;         &lt;dbl&gt;\n## 1 2011-01-01 winter  2011 Jan   Sat         TRUE    no             57.4\n## 2 2011-01-02 winter  2011 Jan   Sun         TRUE    no             58.8\n## 3 2011-01-03 winter  2011 Jan   Mon         FALSE   no             46.5\n## 4 2011-01-04 winter  2011 Jan   Tue         FALSE   no             46.8\n## 5 2011-01-05 winter  2011 Jan   Wed         FALSE   no             48.7\n## 6 2011-01-06 winter  2011 Jan   Thu         FALSE   no             47.1\n## # ‚Ñπ 7 more variables: temp_feel &lt;dbl&gt;, humidity &lt;dbl&gt;, windspeed &lt;dbl&gt;,\n## #   weather_cat &lt;chr&gt;, riders_casual &lt;dbl&gt;, riders_registered &lt;dbl&gt;,\n## #   riders_total &lt;dbl&gt;\n\n\nA case represents a day of the year.\nWe have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.\nLots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nThe distribution of the riders_registered variable looks fairly symmetric. On average there are about 3600 registered riders per day (mean = 3656, median = 3662). On any given day, the number of registered riders is about 1560 from the mean. There seem to be a small number of low outliers (minimum ridership was 20).\n\nggplot(bikes, aes(x = riders_registered)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(y = riders_registered)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nsummary(bikes$riders_registered)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##      20    2497    3662    3656    4776    6946\n\nbikes %&gt;% \n    summarize(sd(riders_registered))\n## # A tibble: 1 √ó 1\n##   `sd(riders_registered)`\n##                     &lt;dbl&gt;\n## 1                   1560.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe‚Äôd like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nScatterplot (outcome and predictor are both quantitative)\n\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nIf we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet‚Äôs fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3681.8  -928.3   -98.6   904.9  3496.7 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\n## temp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1267 on 428 degrees of freedom\n## Multiple R-squared:  0.2949, Adjusted R-squared:  0.2933 \n## F-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\n## temp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\nE[riders_registered | temp_feel] = -2486.41180 + 86.49251 * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders‚Äîa negative number of riders doesn‚Äôt make sense! This results because of extrapolation‚Äî0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don‚Äôt worry about the syntax ‚Äì we haven‚Äôt learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## # A tibble: 1 √ó 2\n##   riders_registered temp_feel\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      53.8\n\n\nMore riders than expected ‚Äì the point is far above the trend line\n-2486.41180 + 86.49251 * 53.816 = 2168.269\nWe get the same result with predict():\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n##        1 \n## 2168.269\n\n\nresidual = 5665 - 2168.269 = 3496.731. On August 17, 2012, there were 3496.731 more riders than would be expected from our model.\n\nPositive residuals are above the trend line‚Äîwe under-estimate ridership.\nNegative residuals are below the trend line‚Äîwe over-estimate ridership.\n\nOn an 85 degree day, we would predict 4865.452 riders. Even though we can compute this prediction, it‚Äôs not a good idea because of extrapolation‚Äìthe data that we used to fit our model was filtered to days less than 80 degrees.\n\n\n-2486.41180 + 86.49251 * 85\n## [1] 4865.452\npredict(bike_mod, newdata = data.frame(temp_feel = 85))\n##        1 \n## 4865.451",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nIf we had measured temperature in degrees Celsius rather than degrees Fahrenheit, both the intercept and slope should change. The intercept would now represent 0 degrees Celsius (32 degrees Fahrenheit) and a one unit change in temperature is now 1 degree Celsius (1.8 degrees Fahrenheit).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet‚Äôs pull together everything that you‚Äôve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\nggplot(bikes, aes(x = windspeed, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\n\n\n\n\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\nbike_mod2 &lt;- lm(riders_registered ~ windspeed, data = bikes)\n\n# Get a short summary of this model\ncoef(summary(bike_mod2))\n##               Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) 4490.09761  149.65992 30.002005 2.023179e-129\n## windspeed    -65.34145   10.86299 -6.015053  2.844453e-09\n\n\nThere‚Äôs a weak, negative relationship ‚Äì ridership tends to be smaller on windier days.\nE[riders_registered | windspeed] = 4490.09761 - 65.34145 windspeed\n\nIntercept: On days with no wind, we‚Äôd expect around 4490 riders. (0 is a little below the minimum of the observed data, but not by much! So extrapolation in interpreting the intercept isn‚Äôt a huge concern.)\nSlope: Every 1mph increase in windspeed is associated with a ridership decrease of 65 riders on average.\n\nSee the code below to predict ridership on August 17, 2012 and calculate the corresponding residual. Note that this residual is smaller than the residual from the temperature model (that residual was 3496.731). This indicates that August 17 was more of an outlier in ridership given the temperature than the windspeed.\n\n\nbikes %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, windspeed)\n## # A tibble: 1 √ó 2\n##   riders_registered windspeed\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      15.5\n\n# prediction\n4490.09761 - 65.34145 * 15.50072\n## [1] 3477.258\n\n# residual \n5665 - 3477.258\n## [1] 2187.742",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We‚Äôll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nsummarize() calculates numerical summaries of variables (columns).\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 √ó 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nselect() selects variables (columns).\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 √ó 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 √ó 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nfilter() keeps only days (rows) that meet the given condition(s).\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\nnew_bikes %&gt;% \n    select(humidity, day_of_week)\n## # A tibble: 10 √ó 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information about the humidity and day of week using a different approach\nnew_bikes %&gt;% \n    select(-date, -temp_feel, -riders_registered)\n## # A tibble: 10 √ó 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information for Sundays\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\")\n## # A tibble: 2 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-02      63.8    0.696               670 Sun        \n## 2 2011-01-09      42.5    0.434               768 Sun\n\n# Keep only information for Sundays with temperatures below 50\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\", temp_feel &lt; 50)\n## # A tibble: 1 √ó 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-09      42.5    0.434               768 Sun\n\n# Calculate the maximum and minimum temperatures\nnew_bikes %&gt;% \n    summarize(min(temp_feel), max(temp_feel))\n## # A tibble: 1 √ó 2\n##   `min(temp_feel)` `max(temp_feel)`\n##              &lt;dbl&gt;            &lt;dbl&gt;\n## 1             42.5             64.7",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-3",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-3",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nUse an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n## # A tibble: 6 √ó 21\n##   Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n##   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n## 1 Natalya Po‚Ä¶ F     D     Raw        37           58.4          NA          NA  \n## 2 Fatima Rod‚Ä¶ F     SBD   Single-p‚Ä¶  NA           74.8          NA          NA  \n## 3 Josh Kelley M     SBD   Single-p‚Ä¶  NA           72.4         147.         97.5\n## 4 Timothy Ca‚Ä¶ M     D     Raw        16           72.9          NA          NA  \n## 5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n## 6 Lucas Wegr‚Ä¶ M     B     Raw        23.5        103.           NA         188. \n## # ‚Ñπ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n## #   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n## #   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n## [1] 100000     21\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren‚Äôt detected by the web scraper used by the maintainers of the Open Powerlifting database. They don‚Äôt describe in detail the process used for transferring PDFs of results to their database, so it‚Äôs unclear what errors in transcription might have resulted. Still, it‚Äôs worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet‚Äôs get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\n\n\nlifts %&gt;%\n  ggplot(aes(SWR)) +\n  geom_histogram(bins = 10, col = \"black\")\n\n\n\n\n\n\n\n\nlifts %&gt;% summarize(mean(SWR, na.rm = TRUE), min(SWR, na.rm = TRUE), max(SWR, na.rm = TRUE), sd(SWR, na.rm = TRUE))\n## # A tibble: 1 √ó 4\n##   `mean(SWR, na.rm = TRUE)` `min(SWR, na.rm = TRUE)` `max(SWR, na.rm = TRUE)`\n##                       &lt;dbl&gt;                    &lt;dbl&gt;                    &lt;dbl&gt;\n## 1                      4.42                    0.183                     12.5\n## # ‚Ñπ 1 more variable: `sd(SWR, na.rm = TRUE)` &lt;dbl&gt;\n\n\nWrite a good paragraph interpreting the plot and numerical summaries.\n\nStrength-to-weight (SWR) ratio ranges from 0.18 to 12.46, with a mean SWR of 4.4. SWR varies about 2.08 units above and below the mean. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe‚Äôd like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a ‚Äúpoint cloud‚Äù) allows us to do this! The code below creates a scatterplot of body weight vs.¬†SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\na & b. In our plot aesthetics, we now have two variables listed (an ‚Äúx‚Äù and a ‚Äúy‚Äù) as opposed to just a single variable. The ‚Äúgeom‚Äù for a scatterplot is geom_point. Otherwise, the code structure remains very similar!\n\nIn general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term ‚Äúweak‚Äù).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nThis doesn‚Äôt change my answer much (but it may have changed yours, and that‚Äôs okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.\nI would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on very few data points. Those data points with low body weights aren‚Äôt enough to convince me that the relationship couldn‚Äôt be roughly linear between body weight and SWR.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\n\nI would describe the correlation between body weight and SWR as weak and negative.\nI‚Äôll guess -0.1, since the line is negative, and the points are very dispersed around the line!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## # A tibble: 1 √ó 1\n##   `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n##                                            &lt;dbl&gt;\n## 1                                        -0.0392\n\nSo close to our guess!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\n\n# correlation between x1, y1\nanscombe %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1   0.8164205\n\n# correlation between x2, y2\nanscombe %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1   0.8162365\n\n# correlation between x3, y3\nanscombe %&gt;% summarize(cor(x3, y3))\n##   cor(x3, y3)\n## 1   0.8162867\n\n# correlation between x4, y4\nanscombe %&gt;% summarize(cor(x4, y4))\n##   cor(x4, y4)\n## 1   0.8165214\n\n\nEach of these correlations are nearly the same!\nEach of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.\n\n\n\n# scatterplot: x1, y1\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x2, y2\nanscombe %&gt;%\n  ggplot(aes(x = x2, y = y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x3, y3\nanscombe %&gt;%\n  ggplot(aes(x = x3, y = y3)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x4, y4\nanscombe %&gt;%\n  ggplot(aes(x = x4, y = y4)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe message of this exercise is that data visualization is important in addition to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\n\n\n\n# scatterplot\ndat %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between x and y is moderately strong and negative.\nI‚Äôll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x, y))\n##    cor(x, y)\n## 1 -0.8295483\n\n\n\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\n\n\n\n# scatterplot\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1  -0.8573567\n\nOur correlation stayed roughly the same with the addition of this new point!\n\n\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\n\n\n\n# scatterplot\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat_new2 %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1  -0.2924792\n\nThe correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!\n\nThe takeaway message here is that even though both of these additional points might be considered ‚Äúoutliers‚Äù because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be influential because it changes the observed relationship between all x‚Äôs and y‚Äôs much more than the first point we considered. Not all ‚Äúoutliers‚Äù are considered equal!\n\n\n\n\n\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Homeworks",
    "section": "",
    "text": "‚Ä¶due in class!\n\nHW 1, due Monday, 02/02"
  },
  {
    "objectID": "pp.html",
    "href": "pp.html",
    "title": "Homeworks",
    "section": "",
    "text": "Practice Problem sets are desinged to help you explore and practice beyond the class examples and exercises. I would highly recommend you to complete the exercises in PPs as you finish them in the class. Make sure, at least to complete all the PPs as soon as we finish one Unit.\n\nPP Unit 01, PP Unit 01 Solution\nPP Unit 02, PP Unit 02 Solution"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "The (tentative) course schedule below will be filled in throughout the semester. For each day, there will be written on what is due ahead of class time OR whats‚Äô the big thing (like quizzes!). The ‚ÄúAnnouncements‚Äù column is (hopefully) self-explanatory. Any urgent announcements will be made over email (moodle).\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\n\n\nMonday\nWednesday\nFriday\nAnnouncements\n\n\n\n\nEnjoy, no class\n01/21: First day of class! Unit 01: Introduction  Before class:  - Read the course syllabus. I will assume that you understand all course policies beginning on Wednesday!  - Familiarize yourself with Canvas/Moodle and the course website\n01/23: Unit 02: Descriptive Statistics  Before class:  - Do either the readings or videos (Links in the Moodle checkpoint quiz)  - Complete today‚Äôs checkpoint on Canvas/Moodle \nWelcome (back) to campus!\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\n\n\nMonday\nWednesday\nFriday\nAnnouncements\n\n\n\n\n01/26: Unit 02: Descriptive Statistics  Before class:  - Do either the readings or videos (Links in the Moodle checkpoint quiz)  - Complete today‚Äôs checkpoint on Canvas/Moodle \n01/28: Descriptive Statistics\n01/29: Unit 03: Simple Linear Regresion  Before class: Do either the readings or videos (Links in the Canvas/Moodle checkpoint quiz)  - Complete today‚Äôs checkpoint on Moodle \n- HW#1 is posted on the Homeworks tab (due Monday, Feb 02, in class)"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html",
    "href": "template_qmds/03-slr-introduction-notes.html",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables\n\n\n\n\nChoose either the reading or the videos to go through after class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#learning-goals",
    "href": "template_qmds/03-slr-introduction-notes.html#learning-goals",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#readings-and-videos",
    "href": "template_qmds/03-slr-introduction-notes.html#readings-and-videos",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through after class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the ‚ÄúActivities‚Äù subfolder of your ‚ÄúSTAT155‚Äù folder."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-1-get-to-know-the-data",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green ‚ÄúC‚Äù button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the ‚ÄúHow does this site work? Do you just download results from the federations?‚Äù question. What do you learn about data quality and completeness from this response?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-2-mutating-our-data",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-2-mutating-our-data",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n## Error in `mutate()`:\n## ‚Ñπ In argument: `NEW_VARIABLE_NAME = Age/BestSquatKg`.\n## Caused by error:\n## ! object 'BestSquatKg' not found\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet‚Äôs get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe‚Äôd like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a ‚Äúpoint cloud‚Äù) allows us to do this! The code below creates a scatterplot of body weight vs.¬†SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ‚Ñπ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nThis is your first bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we‚Äôve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?)."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ‚Ñπ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e.¬†would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-6-correlation",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-6-correlation",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a ‚Äúcorrelation coefficient‚Äù or ‚ÄúPearson‚Äôs correlation‚Äù). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a ‚ÄúMath Box‚Äù. You‚Äôll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e.¬†how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e.¬†does y go ‚Äúup‚Äù when x goes ‚Äúup‚Äù (positive), or does y go ‚Äúdown‚Äù when x goes ‚Äúup‚Äù (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ‚Ñπ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b)."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-7-computing-correlation-in-r",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-7-computing-correlation-in-r",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## Error in `summarize()`:\n## ‚Ñπ In argument: `cor(SWR, BodyweightKg, use = \"complete.obs\")`.\n## Caused by error:\n## ! object 'SWR' not found\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-8-limitations-of-correlation",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-8-limitations-of-correlation",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We‚Äôll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we‚Äôll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn‚Äôt obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you‚Äôd like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#reflection",
    "href": "template_qmds/03-slr-introduction-notes.html#reflection",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today‚Äôs activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-9-lines-of-best-fit",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-9-lines-of-best-fit",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we‚Äôve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is ‚Äúbest‚Äù, and what does ‚Äúbest‚Äù even mean?\nFor this exercise, we‚Äôll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\n\n\n\n\n\n\n\nDescribe the line that you see. Do you think the line is ‚Äúgood‚Äù? What are you using to define ‚Äúgood‚Äù?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we‚Äôll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\n\n\n\n\n\n\n\nIt‚Äôs usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\n\n\n\n\n\n\n\nIn the next activity, we‚Äôll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We‚Äôll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-10-correlation-and-extreme-values",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we‚Äôll explore how correlation changes with the addition of extreme values, or observations. We‚Äôll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs.¬†y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs.¬†y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs.¬†y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#done",
    "href": "template_qmds/03-slr-introduction-notes.html#done",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer ‚Äì check that your work translated correctly; and (3) Outside RStudio, navigate to your ‚ÄòActivities‚Äô subfolder within your ‚ÄòSTAT155‚Äô folder and locate the HTML file ‚Äì you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‚ÄòStop‚Äô button in the ‚ÄòBackground Jobs‚Äô pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  }
]